{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226bda1c-77f4-4c24-963f-5c7ddf0b9794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Comparison Leaderboard:\n",
      "     Model  Scheme_Code                                          Fund_Name  \\\n",
      "8     LSTM       100047         Aditya Birla Sun Life Liquid Fund - Growth   \n",
      "2    ARIMA       100047         Aditya Birla Sun Life Liquid Fund - Growth   \n",
      "5  Prophet       100047         Aditya Birla Sun Life Liquid Fund - Growth   \n",
      "4  Prophet       100048  Aditya Birla Sun Life Liquid Fund -Institution...   \n",
      "7     LSTM       100048  Aditya Birla Sun Life Liquid Fund -Institution...   \n",
      "\n",
      "     MAE   RMSE  R2_Score  \n",
      "8  1.040  1.310     0.978  \n",
      "2  3.492  5.094     0.665  \n",
      "5  4.911  6.517     0.454  \n",
      "4  0.027  0.039     0.284  \n",
      "7  0.030  0.040     0.248  \n",
      "Final comparison saved to: C:/Users/BALA/OneDrive - University of Hertfordshire/Desktop/final project/app/data/results/final_model_comparison.csv\n",
      "\n",
      "Best Forecasting Model Per Fund:\n",
      "                                           Fund_Name    Model   RMSE\n",
      "0         Aditya Birla Sun Life Liquid Fund - Growth     LSTM  1.310\n",
      "1  Aditya Birla Sun Life Liquid Fund -Institution...  Prophet  0.039\n",
      "2     Aditya Birla Sun Life Liquid Fund -weekly IDCW  Prophet  0.028\n",
      "\n",
      " Recommendations saved to: C:/Users/BALA/OneDrive - University of Hertfordshire/Desktop/final project/app/data/results/model_recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "# model_comparison.ipynb or model_comparison.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to leaderboard files (exported by arima_model.py, prophet_model.py, lstm_model.py)\n",
    "path_arima = \"C:/Users/BALA/OneDrive - University of Hertfordshire/Desktop/final project/app/data/results/arima_leaderboard.csv\"\n",
    "path_prophet = \"C:/Users/BALA/OneDrive - University of Hertfordshire/Desktop/final project/app/data/results/prophet_leaderboard.csv\"\n",
    "path_lstm = \"C:/Users/BALA/OneDrive - University of Hertfordshire/Desktop/final project/app/data/results/lstm_leaderboard.csv\"\n",
    "\n",
    "# Load leaderboards\n",
    "leaderboard_df = pd.read_csv(path_arima)\n",
    "leaderboard_prophet = pd.read_csv(path_prophet)\n",
    "leaderboard_lstm = pd.read_csv(path_lstm)\n",
    "\n",
    "# Combine with model name tagging\n",
    "combined = pd.concat([\n",
    "    leaderboard_df.assign(Model='ARIMA'),\n",
    "    leaderboard_prophet.assign(Model='Prophet'),\n",
    "    leaderboard_lstm.assign(Model='LSTM')\n",
    "], ignore_index=True)\n",
    "\n",
    "# Reorder columns correctly\n",
    "final_leaderboard = combined[['Model', 'Scheme_Code', 'Fund_Name', 'MAE', 'RMSE', 'R2_Score']]\n",
    "\n",
    "# Sort by Fund_Name then RMSE for cleaner comparison\n",
    "final_leaderboard = final_leaderboard.sort_values(by=['Fund_Name', 'RMSE'])\n",
    "\n",
    "# Display leaderboard\n",
    "print(\"\\nFinal Model Comparison Leaderboard:\")\n",
    "print(final_leaderboard.head())\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"C:/Users/BALA/OneDrive - University of Hertfordshire/Desktop/final project/app/data/results/final_model_comparison.csv\"\n",
    "final_leaderboard.to_csv(output_path, index=False)\n",
    "print(f\"Final comparison saved to: {output_path}\")\n",
    "\n",
    "# Best model per fund\n",
    "best_models = final_leaderboard.loc[final_leaderboard.groupby('Fund_Name')['RMSE'].idxmin()].reset_index(drop=True)\n",
    "print(\"\\nBest Forecasting Model Per Fund:\")\n",
    "print(best_models[['Fund_Name', 'Model', 'RMSE']].head())\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = []\n",
    "for fund in final_leaderboard['Fund_Name'].unique():\n",
    "    fund_data = final_leaderboard[final_leaderboard['Fund_Name'] == fund]\n",
    "    best_model_row = fund_data.sort_values(by='RMSE').iloc[0]\n",
    "    \n",
    "    rec = {\n",
    "        'Fund_Name': fund,\n",
    "        'Recommended_Model': best_model_row['Model'],\n",
    "        'Reason': f\"{best_model_row['Model']} gave best RMSE ({best_model_row['RMSE']:.2f}) and RÂ² ({best_model_row['R2_Score']:.2f})\"\n",
    "    }\n",
    "    recommendations.append(rec)\n",
    "\n",
    "rec_df = pd.DataFrame(recommendations)\n",
    "\n",
    "# Save recommendations\n",
    "rec_output = \"C:/Users/BALA/OneDrive - University of Hertfordshire/Desktop/final project/app/data/results/model_recommendations.csv\"\n",
    "rec_df.to_csv(rec_output, index=False)\n",
    "print(f\"\\n Recommendations saved to: {rec_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc04c8-ebcd-4d7c-b2a2-22f29901094b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
